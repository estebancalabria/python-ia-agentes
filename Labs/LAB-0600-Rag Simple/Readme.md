# Laboratorio: Sistema RAG B谩sico sin OpenAI con Gradio 

## Introducci贸n 

En este laboratorio, aprenderemos a crear un **sistema RAG (Retrieval-Augmented Generation) b谩sico** que:

- Cargue documentos
- Genere embeddings
- Recupere informaci贸n relevante seg煤n la pregunta

Todo esto **sin usar OpenAI**, solo Python y [Gradio](https://gradio.app).

## Requisitos 

- Cuenta de Google para usar Google Colab
- Conocimientos b谩sicos de Python

## Paso 1: Configurar el Entorno 

Instalamos las librer铆as necesarias:

'''python!pip install gradio
!pip install sentence-transformers</code>

## Paso 2: Importar Bibliotecas 

```python
import gradio as gr
from sentence_transformers import SentenceTransformer, util
```

## Paso 3: Configurar el Modelo de Embeddings 

```python
# Modelo para generar embeddings
modelo_embeddings = SentenceTransformer('all-MiniLM-L6-v2')
```

## Paso 4: Cargar Documentos 

Para este ejemplo, creamos algunos documentos de prueba:

```python
documentos = [
    "Python es un lenguaje de programaci贸n muy popular.",
    "Gradio permite crear interfaces web para tus modelos de machine learning.",
    "Los modelos de lenguaje pueden usar embeddings para buscar informaci贸n relevante."
]

# Generar embeddings de los documentos
embeddings_docs = modelo_embeddings.encode(documentos, convert_to_tensor=True)
```

## Paso 5: Funci贸n de Recuperaci贸n de Contexto 

```python
def recuperar_contexto(pregunta, top_k=2):
    # Generar embedding de la pregunta
    embedding_pregunta = modelo_embeddings.encode(pregunta, convert_to_tensor=True)
    
    # Calcular similitud coseno
    resultados = util.cos_sim(embedding_pregunta, embeddings_docs)[0]
    
    # Obtener los 铆ndices de los documentos m谩s similares
    top_indices = resultados.topk(top_k).indices
    
    # Retornar los documentos relevantes
    contexto = "\n".join([documentos[i] for i in top_indices])
    return contexto
```

## Paso 6: Funci贸n para Consultar el Sistema RAG 

```python
def consulta_rag(pregunta):
    contexto = recuperar_contexto(pregunta)
    respuesta = f"Contexto relevante encontrado:\n{contexto}"
    return respuesta
```

## Paso 7: Crear la Interfaz con Gradio 

```python
interfaz = gr.Interface(
    fn=consulta_rag,
    inputs="text",
    outputs="text",
    title="Sistema RAG B谩sico",
    description="Introduce una pregunta y el sistema mostrar谩 los fragmentos m谩s relevantes de los documentos."
)
```

## Paso 8: Lanzar la Interfaz 

```python
interfaz.launch()
```

## C贸digo Completo З

```python

!pip install gradio
!pip install sentence-transformers

import gradio as gr
from sentence_transformers import SentenceTransformer, util

# Configurar modelo de embeddings
modelo_embeddings = SentenceTransformer('all-MiniLM-L6-v2')

# Documentos de ejemplo
documentos = [
    "Python es un lenguaje de programaci贸n muy popular.",
    "Gradio permite crear interfaces web para tus modelos de machine learning.",
    "Los modelos de lenguaje pueden usar embeddings para buscar informaci贸n relevante."
]

# Generar embeddings de los documentos
embeddings_docs = modelo_embeddings.encode(documentos, convert_to_tensor=True)

# Funci贸n de recuperaci贸n de contexto
def recuperar_contexto(pregunta, top_k=2):
    embedding_pregunta = modelo_embeddings.encode(pregunta, convert_to_tensor=True)
    resultados = util.cos_sim(embedding_pregunta, embeddings_docs)[0]
    top_indices = resultados.topk(top_k).indices
    contexto = "\n".join([documentos[i] for i in top_indices])
    return contexto

# Funci贸n de consulta RAG
def consulta_rag(pregunta):
    contexto = recuperar_contexto(pregunta)
    respuesta = f"Contexto relevante encontrado:\n{contexto}"
    return respuesta

# Crear interfaz Gradio
interfaz = gr.Interface(
    fn=consulta_rag,
    inputs="text",
    outputs="text",
    title="Sistema RAG B谩sico",
    description="Introduce una pregunta y el sistema mostrar谩 los fragmentos m谩s relevantes de los documentos."
)

# Lanzar interfaz
interfaz.launch()
```

## Conclusi贸n 

隆Listo! Ahora tienes un **sistema RAG b谩sico sin depender de OpenAI**.  

- Puedes probar con tus propios documentos
- Hacer preguntas y ver qu茅 fragmentos son m谩s relevantes
- Ideal para laboratorios y experimentaci贸n inicial con embeddings y recuperaci贸n de informaci贸n. 
